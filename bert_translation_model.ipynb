{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1355361,"sourceType":"datasetVersion","datasetId":789090}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T18:23:41.787295Z","iopub.execute_input":"2024-08-13T18:23:41.787707Z","iopub.status.idle":"2024-08-13T18:23:42.829300Z","shell.execute_reply.started":"2024-08-13T18:23:41.787656Z","shell.execute_reply":"2024-08-13T18:23:42.828227Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/hindi-english-parallel-corpus/hindi_english_parallel.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Building a BERT-Based Translation Model with google/mt5-base:**","metadata":{}},{"cell_type":"markdown","source":"google/mt5-baseis a pre-trained multilingual model from the mT5 (Multilingual T5) family, designed for text generation tasks like translation, summarization, and question-answering across multiple languages.","metadata":{}},{"cell_type":"code","source":"#import libraries\nimport pandas as pd\nimport unicodedata\nimport re\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom transformers import MT5ForConditionalGeneration, MT5Tokenizer\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:23:42.831501Z","iopub.execute_input":"2024-08-13T18:23:42.832016Z","iopub.status.idle":"2024-08-13T18:23:48.755132Z","shell.execute_reply.started":"2024-08-13T18:23:42.831981Z","shell.execute_reply":"2024-08-13T18:23:48.754301Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-08-13T21:10:26.109740Z","iopub.execute_input":"2024-08-13T21:10:26.110085Z","iopub.status.idle":"2024-08-13T21:10:26.116357Z","shell.execute_reply.started":"2024-08-13T21:10:26.110057Z","shell.execute_reply":"2024-08-13T21:10:26.115186Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH=15","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:23:48.756213Z","iopub.execute_input":"2024-08-13T18:23:48.756649Z","iopub.status.idle":"2024-08-13T18:23:48.760732Z","shell.execute_reply.started":"2024-08-13T18:23:48.756624Z","shell.execute_reply":"2024-08-13T18:23:48.759720Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Preparing Data:**","metadata":{}},{"cell_type":"code","source":"#The data consists of a large parallel corpus of Hindi and English sentences.\ndf= pd.read_csv(\"/kaggle/input/hindi-english-parallel-corpus/hindi_english_parallel.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:23:48.763195Z","iopub.execute_input":"2024-08-13T18:23:48.763610Z","iopub.status.idle":"2024-08-13T18:23:58.838819Z","shell.execute_reply.started":"2024-08-13T18:23:48.763577Z","shell.execute_reply":"2024-08-13T18:23:58.837843Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"clean the data","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:23:58.840113Z","iopub.execute_input":"2024-08-13T18:23:58.840860Z","iopub.status.idle":"2024-08-13T18:23:58.859562Z","shell.execute_reply.started":"2024-08-13T18:23:58.840824Z","shell.execute_reply":"2024-08-13T18:23:58.858739Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                               hindi  \\\n0    ‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§¶‡•á‡§Ç   \n1                    ‡§è‡§ï‡•ç‡§∏‡•á‡§∞‡•ç‡§∏‡§æ‡§á‡§∏‡§∞ ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§ï   \n2              ‡§®‡§ø‡§ö‡§≤‡•á ‡§™‡§ü‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§´‡•ã‡§≤‡•ç‡§ü ‡§™‡•ç‡§≤‡§ó-‡§á‡§® ‡§ñ‡§æ‡§ï‡§æ   \n3               ‡§ä‡§™‡§∞‡•Ä ‡§™‡§ü‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§´‡•ã‡§≤‡•ç‡§ü ‡§™‡•ç‡§≤‡§ó-‡§á‡§® ‡§ñ‡§æ‡§ï‡§æ   \n4  ‡§â‡§® ‡§™‡•ç‡§≤‡§ó-‡§á‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡•Ç‡§ö‡•Ä ‡§ú‡§ø‡§®‡•ç‡§π‡•á‡§Ç ‡§°‡§ø‡§´‡•ã‡§≤‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§®‡§ø...   \n\n                                          english  \n0  Give your application an accessibility workout  \n1               Accerciser Accessibility Explorer  \n2  The default plugin layout for the bottom panel  \n3     The default plugin layout for the top panel  \n4  A list of plugins that are disabled by default  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hindi</th>\n      <th>english</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§¶‡•á‡§Ç</td>\n      <td>Give your application an accessibility workout</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>‡§è‡§ï‡•ç‡§∏‡•á‡§∞‡•ç‡§∏‡§æ‡§á‡§∏‡§∞ ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§ï</td>\n      <td>Accerciser Accessibility Explorer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>‡§®‡§ø‡§ö‡§≤‡•á ‡§™‡§ü‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§´‡•ã‡§≤‡•ç‡§ü ‡§™‡•ç‡§≤‡§ó-‡§á‡§® ‡§ñ‡§æ‡§ï‡§æ</td>\n      <td>The default plugin layout for the bottom panel</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>‡§ä‡§™‡§∞‡•Ä ‡§™‡§ü‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§´‡•ã‡§≤‡•ç‡§ü ‡§™‡•ç‡§≤‡§ó-‡§á‡§® ‡§ñ‡§æ‡§ï‡§æ</td>\n      <td>The default plugin layout for the top panel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>‡§â‡§® ‡§™‡•ç‡§≤‡§ó-‡§á‡§®‡•ã‡§Ç ‡§ï‡•Ä ‡§∏‡•Ç‡§ö‡•Ä ‡§ú‡§ø‡§®‡•ç‡§π‡•á‡§Ç ‡§°‡§ø‡§´‡•ã‡§≤‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§®‡§ø...</td>\n      <td>A list of plugins that are disabled by default</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def unicodeToAscii(s):\n  return \"\".join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')\ndef normalizeString_for_eng(s):\n    s = str(s)\n    s = unicodeToAscii(s.strip())\n    s = re.sub(r\"[.!?]\", \"\", s)\n    s = re.sub(r\"[^a-zA-Z0-9]+\", r\" \", s)\n    return s.strip()\n\ndef normalizeString_for_hin(s):\n  s = str(s)\n  hindi_chars = \"\\u0900-\\u097F\\u0980-\\u09FF a-zA-Z0-9!? |\"\n  s = re.sub(r\"[^\" + hindi_chars + \"]\", r\" \", s)\n  return s.strip()\n\nlist_of_pairs = []\nfor index, row in df.iterrows():\n    english_sentence =   normalizeString_for_eng(row[\"english\"])\n    hindi_sentence =  normalizeString_for_hin(row[\"hindi\"])\n    if len( english_sentence.split(' ')) < MAX_LENGTH and len(hindi_sentence.split(' '))< MAX_LENGTH:\n      sentence_pair = [hindi_sentence, english_sentence]\n      list_of_pairs.append(sentence_pair)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:23:58.860674Z","iopub.execute_input":"2024-08-13T18:23:58.861013Z","iopub.status.idle":"2024-08-13T18:26:35.703002Z","shell.execute_reply.started":"2024-08-13T18:23:58.860981Z","shell.execute_reply":"2024-08-13T18:26:35.702032Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Split the cleaned dataset into training, validation, and test sets","metadata":{}},{"cell_type":"code","source":"train_set, df_temp = train_test_split(list_of_pairs, test_size=0.5, random_state=42)\nval_set, test_set = train_test_split(df_temp, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:26:35.704187Z","iopub.execute_input":"2024-08-13T18:26:35.704471Z","iopub.status.idle":"2024-08-13T18:26:36.262427Z","shell.execute_reply.started":"2024-08-13T18:26:35.704446Z","shell.execute_reply":"2024-08-13T18:26:36.261424Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"put our train and validation in dataset object","metadata":{}},{"cell_type":"code","source":"# convert the training and validation sets into dictionaries and then into Datasets\ndataset = DatasetDict({\n    'train': Dataset.from_dict({\n        'sentence1': [pair[0] for pair in train_set],\n        'sentence2': [pair[1] for pair in train_set]\n    }),\n    'validation': Dataset.from_dict({\n        'sentence1': [pair[0] for pair in val_set],\n        'sentence2': [pair[1] for pair in val_set]\n    })\n})","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:26:36.263898Z","iopub.execute_input":"2024-08-13T18:26:36.264189Z","iopub.status.idle":"2024-08-13T18:26:38.282600Z","shell.execute_reply.started":"2024-08-13T18:26:36.264165Z","shell.execute_reply":"2024-08-13T18:26:38.281832Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:26:38.284086Z","iopub.execute_input":"2024-08-13T18:26:38.284478Z","iopub.status.idle":"2024-08-13T18:26:38.290301Z","shell.execute_reply.started":"2024-08-13T18:26:38.284445Z","shell.execute_reply":"2024-08-13T18:26:38.289438Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2'],\n        num_rows: 489369\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2'],\n        num_rows: 391495\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Load the model and tokenizer**","metadata":{}},{"cell_type":"code","source":"model_name = \"google/mt5-base\"\ntokenizer = MT5Tokenizer.from_pretrained(model_name)\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:26:38.293418Z","iopub.execute_input":"2024-08-13T18:26:38.293710Z","iopub.status.idle":"2024-08-13T18:26:56.309076Z","shell.execute_reply.started":"2024-08-13T18:26:38.293666Z","shell.execute_reply":"2024-08-13T18:26:56.307924Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc02cf02cec407f94485afee7581716"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1dd3ba4cf164a359d52442a27ffc288"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c195da0bd81d4bf1bc1b5d31f6923478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a0d4f96e5d04264bfa3f7d12a746788"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef20f893c96f435ca7473cf540d0e5ac"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a36533b9138e4da188f8a8293fdf2aa4"}},"metadata":{}}]},{"cell_type":"markdown","source":"Tokenize the sentence pair with truncation and padding to the max length","metadata":{}},{"cell_type":"code","source":"def tokenize_sentences(sentences, tokenizer=tokenizer,max_length=30 ):\n\n  for example in range(1):\n    hindi_sentence =sentences[\"sentence1\"]\n    english_sentence = sentences['sentence2']\n    encoded_pair = tokenizer(\n        text=hindi_sentence,\n        \n        text_target=english_sentence,\n        return_tensors=\"pt\",\n        max_length=max_length,\n        padding=\"max_length\",  \n        truncation=True,        \n        add_special_tokens=True,\n        return_attention_mask=True   \n    )\n\n  return {\n        'input_ids': encoded_pair['input_ids'].squeeze(),  # Remove extra dimensions\n        'attention_mask': encoded_pair['attention_mask'].squeeze(),\n        'labels': encoded_pair['labels'].squeeze()\n    }","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:26:56.310657Z","iopub.execute_input":"2024-08-13T18:26:56.311029Z","iopub.status.idle":"2024-08-13T18:26:56.318494Z","shell.execute_reply.started":"2024-08-13T18:26:56.310996Z","shell.execute_reply":"2024-08-13T18:26:56.317651Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tokenize_sentences(dataset[\"train\"][2])","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:26:56.319739Z","iopub.execute_input":"2024-08-13T18:26:56.320117Z","iopub.status.idle":"2024-08-13T18:26:56.348966Z","shell.execute_reply.started":"2024-08-13T18:26:56.320081Z","shell.execute_reply":"2024-08-13T18:26:56.348072Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([29196, 12946,  1665,     1,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n 'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0]),\n 'labels': tensor([  259, 24191,     1,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0])}"},"metadata":{}}]},{"cell_type":"code","source":"#Applying the tokenize_sentences function to each example in the dataset. \ntokenized_datasets = dataset.map(tokenize_sentences, batched=True, remove_columns=dataset[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:26:56.350182Z","iopub.execute_input":"2024-08-13T18:26:56.350548Z","iopub.status.idle":"2024-08-13T18:30:21.401570Z","shell.execute_reply.started":"2024-08-13T18:26:56.350515Z","shell.execute_reply":"2024-08-13T18:30:21.400728Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/489369 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aab8dfaa099642299a3a3fa0edfb3d85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/391495 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5a8b9c8c95742b29b01beeacd564745"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **Training the model:**","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir='./results',           \n    per_device_train_batch_size=40,    \n    per_device_eval_batch_size=40,\n    num_train_epochs=1,               \n    weight_decay=0.01,              \n    logging_dir='./logs',             \n    logging_steps=10,\n    evaluation_strategy=\"epoch\",     \n    save_strategy=\"epoch\"             \n)\n \ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'] ,\n    eval_dataset=tokenized_datasets['validation'],   \n    tokenizer=tokenizer\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T18:31:45.107728Z","iopub.execute_input":"2024-08-13T18:31:45.108584Z","iopub.status.idle":"2024-08-13T21:06:10.581799Z","shell.execute_reply.started":"2024-08-13T18:31:45.108546Z","shell.execute_reply":"2024-08-13T21:06:10.580860Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2024-08-13 18:31:47.055133: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-13 18:31:47.055276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-13 18:31:47.192049: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240813_183514-8uukol1t</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/soulless597-github/huggingface/runs/8uukol1t' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/soulless597-github/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/soulless597-github/huggingface' target=\"_blank\">https://wandb.ai/soulless597-github/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/soulless597-github/huggingface/runs/8uukol1t' target=\"_blank\">https://wandb.ai/soulless597-github/huggingface/runs/8uukol1t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12235' max='12235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12235/12235 2:30:36, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.762000</td>\n      <td>0.607788</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=12235, training_loss=1.2622004191535416, metrics={'train_runtime': 9251.0847, 'train_samples_per_second': 52.899, 'train_steps_per_second': 1.323, 'total_flos': 3.438140662674432e+16, 'train_loss': 1.2622004191535416, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Model Evaluation and Metrics:**","metadata":{}},{"cell_type":"markdown","source":"Function to Evaluate and Decode Text Using  The Trained   Model","metadata":{}},{"cell_type":"code","source":"def evaluate(text,model=model, tokenizer=tokenizer, max_length=30 ):\n     \n    with torch.no_grad():\n         \n        inputs = tokenizer(\n            text, \n            return_tensors=\"pt\", \n            max_length=max_length, \n            padding=\"max_length\", \n            truncation=True\n        ).to(device)\n\n         \n        outputs = model.generate(\n            input_ids=inputs['input_ids'],\n            attention_mask=inputs['attention_mask']\n        )\n\n        \n        predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return predicted_text","metadata":{"execution":{"iopub.status.busy":"2024-08-13T21:10:08.024820Z","iopub.execute_input":"2024-08-13T21:10:08.025150Z","iopub.status.idle":"2024-08-13T21:10:08.032744Z","shell.execute_reply.started":"2024-08-13T21:10:08.025123Z","shell.execute_reply":"2024-08-13T21:10:08.031580Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Calculate BLEU  for Model Output","metadata":{}},{"cell_type":"code","source":"# Calculate the average BLEU score for a dataset of sentence pairs.\ndef BLUE_SCORE(data, batch_size):\n    bleu_scores = []\n    \n   \n    data = list(data.values())\n    data = list(zip(*data))\n    \n    num_batches = (len(data) + batch_size - 1) // batch_size   \n    \n    for i in range(num_batches):\n         \n        start_index = i * batch_size\n        end_index = min(start_index + batch_size, len(data))\n        \n        batch_data = data[start_index:end_index]   \n        \n        for input_sentence, target_sentence in batch_data:\n            \n            output_words = evaluate(input_sentence)\n            output_sentence = ' '.join(output_words)\n            \n            target_tokens = target_sentence.split()\n            output_tokens = output_sentence.split()\n \n            bleu_score = sentence_bleu([target_tokens], output_tokens)\n            bleu_scores.append(bleu_score)\n     \n    average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n    \n    return average_bleu_score","metadata":{"execution":{"iopub.status.busy":"2024-08-13T22:58:29.331138Z","iopub.execute_input":"2024-08-13T22:58:29.331796Z","iopub.status.idle":"2024-08-13T22:58:29.341036Z","shell.execute_reply.started":"2024-08-13T22:58:29.331763Z","shell.execute_reply":"2024-08-13T22:58:29.340041Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"average_bleu_score = BLUE_SCORE(dataset[\"validation\"][:10000], 10000)\nprint(f\"The average BLEU score for the evaluated dataset is: {average_bleu_score:.2f}\")\n ","metadata":{"execution":{"iopub.status.busy":"2024-08-13T22:59:23.966060Z","iopub.execute_input":"2024-08-13T22:59:23.966716Z","iopub.status.idle":"2024-08-13T23:22:51.055311Z","shell.execute_reply.started":"2024-08-13T22:59:23.966665Z","shell.execute_reply":"2024-08-13T23:22:51.054216Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"The average BLEU score for the evaluated dataset is: 0.06\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Evaluate Model Predictions on test Set","metadata":{}},{"cell_type":"code","source":"def evaluate_train(model, n=10):\n    for i in range(n):\n\n        pair = random.choice(test_set)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words= evaluate(  pair[0])\n\n        output_sentence = ''.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"execution":{"iopub.status.busy":"2024-08-13T21:12:46.019771Z","iopub.execute_input":"2024-08-13T21:12:46.020134Z","iopub.status.idle":"2024-08-13T21:12:46.027434Z","shell.execute_reply.started":"2024-08-13T21:12:46.020106Z","shell.execute_reply":"2024-08-13T21:12:46.026437Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"evaluate_train(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T21:13:25.022724Z","iopub.execute_input":"2024-08-13T21:13:25.023546Z","iopub.status.idle":"2024-08-13T21:13:25.545410Z","shell.execute_reply.started":"2024-08-13T21:13:25.023515Z","shell.execute_reply":"2024-08-13T21:13:25.544320Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"> ‡§ò‡§®\n= Cube21\n< a\n\n> ‡§™‡•Ç‡§∞‡§æ ‡§¶‡§ø‡§®‡§É\n= All day\n< Full Day\n\n> ‡§∏‡•ç‡§®‡•Ç‡§ú‡§º    S\n= Snooze\n< spool\n\n> ‡§ï‡§æ‡§≤‡§æ ‡§¨‡§æ‡§ú‡§æ‡§∞\n= Black market\n< Black market\n\n> ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§ï‡•ã‡§à ‡§µ‡§∞‡•ç‡§ï‡§∂‡•Ä‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à ‡§ú‡§ø‡§∏‡•á ‡§∏‡§π‡•á‡§ú‡§æ ‡§ú‡§æ ‡§∏‡§ï‡•á\n= You do not have a tab that could be saved\n< You have no toolbar that can be saved\n\n","output_type":"stream"}]}]}